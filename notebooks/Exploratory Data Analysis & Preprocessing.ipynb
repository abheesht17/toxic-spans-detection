{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILE = '../data/tsd_train.csv'\n",
    "TRIAL_FILE = '../data/tsd_trial.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(TRAIN_FILE)\n",
    "trial = pd.read_csv(TRIAL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n      <td>Another violent and aggressive immigrant killi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n      <td>I am 56 years old, I am not your fucking junio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3]</td>\n      <td>Damn, a whole family. Sad indeed.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n      <td>What a knucklehead. How can anyone not know th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7939, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spans    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      spans  \\\n",
       "0  [15, 16, 17, 18, 19, 27, 28, 29, 30, 31]   \n",
       "1                  [29, 30, 31, 32, 33, 34]   \n",
       "2            [166, 167, 168, 169, 170, 171]   \n",
       "3                  [87, 88, 89, 90, 91, 92]   \n",
       "4                                        []   \n",
       "\n",
       "                                                text  \n",
       "0  Because he's a moron and a bigot. It's not any...  \n",
       "1  How about we stop protecting idiots and let na...  \n",
       "2  If people  were  smart, they would  Boycott th...  \n",
       "3  Trump Claimed that Russia will never invade th...  \n",
       "4  As long as your willing to pay a lot more for ...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[15, 16, 17, 18, 19, 27, 28, 29, 30, 31]</td>\n      <td>Because he's a moron and a bigot. It's not any...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[29, 30, 31, 32, 33, 34]</td>\n      <td>How about we stop protecting idiots and let na...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[166, 167, 168, 169, 170, 171]</td>\n      <td>If people  were  smart, they would  Boycott th...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[87, 88, 89, 90, 91, 92]</td>\n      <td>Trump Claimed that Russia will never invade th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[]</td>\n      <td>As long as your willing to pay a lot more for ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(690, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "trial.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spans    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "trial.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "trial.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = pd.concat([train,trial])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n      <td>Another violent and aggressive immigrant killi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n      <td>I am 56 years old, I am not your fucking junio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3]</td>\n      <td>Damn, a whole family. Sad indeed.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n      <td>What a knucklehead. How can anyone not know th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "combo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "spans    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "combo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "combo.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        spans                  text\n",
       "100          [6, 7, 8, 9, 10]          Trump troll!\n",
       "224           [0, 1, 2, 3, 4]                Idiot!\n",
       "276           [0, 1, 2, 3, 4]                 Idiot\n",
       "363  [14, 15, 16, 17, 18, 19]  You can't fix stupid\n",
       "588      [11, 12, 13, 14, 15]     You are an idiot."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>100</th>\n      <td>[6, 7, 8, 9, 10]</td>\n      <td>Trump troll!</td>\n    </tr>\n    <tr>\n      <th>224</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot!</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>[14, 15, 16, 17, 18, 19]</td>\n      <td>You can't fix stupid</td>\n    </tr>\n    <tr>\n      <th>588</th>\n      <td>[11, 12, 13, 14, 15]</td>\n      <td>You are an idiot.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "combo[combo.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                spans   text\n",
       "3770  [0, 1, 2, 3, 4]  Idiot"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3770</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train[train['text']=='Idiot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               spans   text\n",
       "276  [0, 1, 2, 3, 4]  Idiot"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>276</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "trial[trial['text']=='Idiot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = train.merge(trial, how='inner',indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                      spans                  text\n",
       "0  [14, 15, 16, 17, 18, 19]  You can't fix stupid\n",
       "1           [0, 1, 2, 3, 4]                Idiot!\n",
       "2           [0, 1, 2, 3, 4]                 Idiot\n",
       "3          [6, 7, 8, 9, 10]          Trump troll!\n",
       "4      [11, 12, 13, 14, 15]     You are an idiot."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[14, 15, 16, 17, 18, 19]</td>\n      <td>You can't fix stupid</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot!</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3, 4]</td>\n      <td>Idiot</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[6, 7, 8, 9, 10]</td>\n      <td>Trump troll!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[11, 12, 13, 14, 15]</td>\n      <td>You are an idiot.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train[~train.text.isin(merged_df['text'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(7934, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               spans  \\\n",
       "0  [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...   \n",
       "1                       [33, 34, 35, 36, 37, 38, 39]   \n",
       "2                                       [0, 1, 2, 3]   \n",
       "3          [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]   \n",
       "4                       [32, 33, 34, 35, 36, 37, 38]   \n",
       "\n",
       "                                                text  \n",
       "0  Another violent and aggressive immigrant killi...  \n",
       "1  I am 56 years old, I am not your fucking junio...  \n",
       "2                  Damn, a whole family. Sad indeed.  \n",
       "3  What a knucklehead. How can anyone not know th...  \n",
       "4  \"who do you think should do the killing?\"\\n\\nA...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>spans</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n      <td>Another violent and aggressive immigrant killi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n      <td>I am 56 years old, I am not your fucking junio...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3]</td>\n      <td>Damn, a whole family. Sad indeed.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n      <td>What a knucklehead. How can anyone not know th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "new_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv('../data/modified_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: termcolor in /home/crocoder/anaconda3/lib/python3.8/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install termcolor\n",
    "from termcolor import colored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = new_train.iloc[5]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = eval(new_train.iloc[5]['spans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'But, but, but, is NOT a defense.  It\\'s not even a good deflection.  In America today we have Nazis waving the Nazi flag at rallies in our cities. In what capacity does anyone think this is ok and who would not see that as a problem?\\n\\nEnough with the \"Well what about blah blah\" garbage.'"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = list(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continuous_spans(spans):\n",
    "    continuous_spans = []\n",
    "    current_span = []\n",
    "    for i in range(len(spans)):\n",
    "        if current_span == []:\n",
    "            current_span.append(spans[i])\n",
    "            continue\n",
    "        if spans[i]==current_span[-1]+1:\n",
    "            current_span.append(spans[i])\n",
    "        else:\n",
    "            continuous_spans.append(current_span)\n",
    "            current_span = [spans[i]]\n",
    "    if(current_span!=[]):\n",
    "        continuous_spans.append(current_span)\n",
    "    return continuous_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any spaces are marked in the toxic spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_space_count(df):\n",
    "    df['space_count'] = df.apply(lambda x: np.sum([1 if x['text'][i]==' ' else 0 for i in eval(x['spans'])]),axis=1)\n",
    "    return df['space_count'].sum(), df['space_count'].mean(),  df['space_count'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['13278.00', '1.67', '7.72']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in get_space_count(new_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['830.00', '1.20', '4.48']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in get_space_count(trial)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any words are cut across spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_if_word_cut(text,contiguous_spans):\n",
    "    words_cuts = []\n",
    "    for i in contiguous_spans:\n",
    "        words_cut = 0\n",
    "        if i[0]==0 and i[-1]==len(text)-1:\n",
    "            words_cut = 0\n",
    "        elif i[0]==0:\n",
    "            if text[i[-1]]!=' ' and text[i[-1]+1].isalnum():\n",
    "                words_cut+=1\n",
    "        elif i[-1]==len(text)-1:\n",
    "            if text[i[0]]!=' ' and text[i[0]-1].isalnum():\n",
    "                words_cut +=1\n",
    "        else:\n",
    "            if text[i[0]]!=' ' and text[i[0]-1].isalnum():\n",
    "                words_cut +=1\n",
    "            if text[i[-1]]!=' ' and text[i[-1]+1].isalnum():\n",
    "                words_cut +=1\n",
    "        words_cuts.append(words_cut)\n",
    "    return words_cuts     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_cut_count(df):\n",
    "    df['contiguous_spans'] = df.apply(lambda x : get_continuous_spans(eval(x['spans'])),axis=1)\n",
    "    df['words_cut'] = df.apply(lambda x: np.sum(check_if_word_cut(x['text'],x['contiguous_spans'])),axis=1)\n",
    "    return df['words_cut'].sum(),df['words_cut'].mean(),df['words_cut'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['263.00', '0.03', '0.20']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in words_cut_count(new_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['26.00', '0.04', '0.23']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in words_cut_count(trial)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_contiguous_spans(text,contiguous_spans):\n",
    "    return [text[i[0]:i[-1]+1] for i in contiguous_spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      ('Nah!  We can pretend he is a Republican.  Off with his head!  Impeach him!  Recall him! etc, etc, etc.', 102, '[55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]', [[55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67]], ['head!  Impeac'], 1.0),\n",
       "       (\"Roof is not really an ignorant redneck or KKK white trash--his family seemed quite well-off when he was a child and according to reports he was bright in school.   He's clearly not normal--his OCD is likely from Asperger's or autism.  He got into drugs and someone like him, very obviously, should not have been permitted to carry a gun.\", 337, '[22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229]', [[22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37], [162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229]], ['ignorant redneck', \"  He's clearly not normal--his OCD is likely from Asperger's or auti\"], 1.0),\n",
       "       ('Dear world:\\nJust a reminder that none of these folks actually live in Oregon.  Please remember that when you decide to paint our state as a bunch of wackos! \\n\\nSincerely,\\nOregon', 176, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171]], ['Dear world:\\nJust a reminder that none of these folks actually live in Oregon.  Please remember that when you decide to paint our state as a bunch of wackos! \\n\\nSincerely,\\nOr'], 1.0),\n",
       "       ('<Kneeling at the national anthem is highly offensive.>\\nOffensive to whom? The peaceful and lawful exercise of the right to protest ought never be construed as offensive to anyone who loves the Constitution and embraces its values. The sight of some persons kneeling peacefully along side other persons standing peacefully, all in mutual respect, honors the flag in a profound way.\\n<Criticizing it is Trump\\'s right.>\\nAbsolutely; Trump\\'s rights under the Constitution are neither less nor greater than anyone else\\'s. I suppose he has the right, too, to call the protester a \"son of a bitch.\"* However, in doing so, Trump demonstrates his ignorance of and contempt for the Constitution -- as well as his disrespect for the people of the United States.\\n\\n* I wonder if my direct quote of the president\\'s language, used in public, will get past the Civil Comments process.  What a disgrace it is that this vulgar man is President of the United States.', 945, '[485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498]', [[485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498]], ['r greater than'], 1.0),\n",
       "       ('WOW!  You\\'re calling a sick child a \"spigot.\"', 45, '[11, 12, 13, 14, 15, 16, 17, 18, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]', [[11, 12, 13, 14, 15, 16, 17, 18], [23, 24, 25, 26, 27, 28, 29, 30, 31, 32]], ['e callin', 'sick child'], 2.0),\n",
       "       ('Trudeau Jr. supports an international crime of aggression which has killed at least 5 innocent Syrian servicemen.  \\nDISGUSTING.', 127, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123]], ['Trudeau Jr. supports an international crime of aggression which has killed at least 5 innocent Syrian servicemen.  \\nDISGUSTI'], 1.0),\n",
       "       ('The settlement is 100% appropriate.\\nEnding the column by calling Justin Trudeau....faults and all...cowardly....is disgusting.\\nTypical spineless Wente trash. Get rid of this idiot.', 180, '[6, 7, 8, 9, 174, 175, 176, 177, 178]', [[6, 7, 8, 9], [174, 175, 176, 177, 178]], ['ttle', 'idiot'], 2.0),\n",
       "       (\"Those stupid liberals are just awful!!! I mean, how can they think that its fair to infringe on our rights to shoot the gay and latino and black people, and keep the women in the kitchen!\\n\\nI mean, isn't it just an outrage to assume that these people have civil rights???\", 270, '[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 31, 32, 33, 34, 35, 110, 111, 112, 113, 114, 120, 121, 122, 128, 129, 130, 131, 132, 133, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]', [[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], [31, 32, 33, 34, 35], [110, 111, 112, 113, 114], [120, 121, 122], [128, 129, 130, 131, 132, 133], [139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]], ['tupid liberals', 'awful', 'shoot', 'gay', 'latino', 'black people'], 1.0),\n",
       "       ('Black Pride = being black and proud\\nGay Pride = being gay and proud\\nWhite Pride = NAZI!', 87, '[20, 21, 22, 23, 24, 36, 37, 38, 54, 55, 56, 82, 83, 84]', [[20, 21, 22, 23, 24], [36, 37, 38], [54, 55, 56], [82, 83, 84]], ['black', 'Gay', 'gay', 'NAZ'], 1.0),\n",
       "       ('Your comedy not funny. Stupid comedians. Make jokes I think funny.', 66, '[23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]', [[23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]], ['Stupid comedian'], 1.0),\n",
       "       (\"Tiny digits Drumpf, Dr. Strange-glove, a satanic blustering, outrageous fabricator of  lies, blatantly untrustworthy, and the personification of the boy who called wolf,  leader of the free world (Ha!) is going to get us all killed.  It's unfortunate, because Seoul is my favourite city in the world.\", 300, '[72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]', [[72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]], ['fabricator of  lie'], 1.0),\n",
       "       ('aiee soose..........whatever happened to \"you fool around with my wife i goin stab you with my knife?\"', 102, '[7, 8, 9]', [[7, 8, 9]], ['ose'], 1.0),\n",
       "       ('Up until now I thought Trump was a true psychopath but he has at least shown some empathy now.  He may be an idiot but at least he has some feelings which may give a little hope.  On the other hand, our Prime Minister is a complete idiot who may have too much empathy.  Neither country is well served.', 301, '[109, 110, 111, 112, 113, 209, 210, 211, 212, 213, 214, 215, 232, 233, 234, 235, 236]', [[109, 110, 111, 112, 113], [209, 210, 211, 212, 213, 214, 215], [232, 233, 234, 235, 236]], ['idiot', 'Ministe', 'idiot'], 1.0),\n",
       "       (\"It was pathetic when Harper attacked anyone who criticized him with the CRA.  I bet you can't wait to see him behind bars.\", 122, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74], [77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119]], ['It was pathetic when Harper attacked anyone who criticized him with the CRA', \" I bet you can't wait to see him behind bar\"], 1.0),\n",
       "       ('Very hard to defend your position, isn\\'t it fed_up?  It\\'s a position that is becoming less and less popular and one that is an example of \"wrong thinking.\"  Can\\'t really defend the indefensible.  Go back and watch some of Trump\\'s The Apprentice.  He\\'s exactly the same.  Mean, nasty and bullheaded.', 298, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291]], ['Very hard to defend your position, isn\\'t it fed_up?  It\\'s a position that is becoming less and less popular and one that is an example of \"wrong thinking.\"  Can\\'t really defend the indefensible.  Go back and watch some of Trump\\'s The Apprentice.  He\\'s exactly the same.  Mean, nasty and bullh'], 1.0),\n",
       "       ('Neither Kennedy nor Clinton have been shown to have assaulted anyone whereas Trump proudly boasted about how he likes to grab women\\'s genitals and about the \"fact\" that he can get away with it because of his celebrity.', 218, '[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 134, 135, 136, 137, 138, 139, 140, 141]', [[9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23], [134, 135, 136, 137, 138, 139, 140, 141]], ['ennedy nor Clin', 'genitals'], 2.0),\n",
       "       ('burned out for 6 yrs? too bad.  jerk cop should have quit 5 yrs ago....', 71, '[31, 32, 33, 34]', [[31, 32, 33, 34]], [' jer'], 1.0),\n",
       "       (\"I can understand how the white working class thought of this guy as their voice in DC, he's quite the conman and Fox News, Breitbart, et al were pounding the drums for his election.  I cannot understand how the white working class or anyone else can continue to support this treasonous waste of humanity.  He's been bought by the Kremlin.  He didn't need to be bribed with prostitutes in Moscow or anywhere else he visited in the East Block.  Trump was bought by millions in hidden payments for laundering stolen Russian people's money.  The Kremlin is HQ for the Russian KGB-GRU Mafia, Trump sent his little Prince Kushner to the Russian Embassy to get a KGB secure comms link directly to Trump's boss Putin.  Only one reason for wanting a direct comms link with the Kremlin, hiding your conversations from the American people and FBI counter-intell folks.  You've got something to hide.  Trump is a treasonous conman, time for white working class to wake up and chose America over this fool.\", 993, '[691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701]', [[691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701]], [\"rump's boss\"], 1.0),\n",
       "       ('Not a man.  A mouse trying hard to be a rat like Trump.', 55, '[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 40, 41, 42]', [[8, 9, 10, 11, 12, 13, 14, 15, 16, 17], [40, 41, 42]], ['n.  A mous', 'rat'], 2.0),\n",
       "       ('Why the need to act like a petulant child when posting on here?  Grow up and come back in a few years.', 102, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]], ['Why the need to act like a petulant child when posting on here?  Grow up and come back in a few year'], 1.0),\n",
       "       (\"These aren't womens' marches.  They are puppets' marches.  Mindless puppets of the Washington Post, New York Times and the rest of the world's liberati media.  Got to feel sorry for these women.\", 194, '[159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]', [[159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191]], [' Got to feel sorry for these wome'], 1.0),\n",
       "       ('\"Ever since Olbermann and Dan Patrick turned ESPN’s signature program,\"\\n\\nThis was ESPN was at it\\'s absolute best, with Craig Kilborn and Charlie Steiner as well.\\n\\n“ESPN First Take,” was the start of ESPNs downfall, trash show that birthed more trash shows.', 256, '[3, 4, 5, 6, 7, 8, 9, 10, 244, 245, 246, 247, 248]', [[3, 4, 5, 6, 7, 8, 9, 10], [244, 245, 246, 247, 248]], ['er since', 'trash'], 1.0),\n",
       "       ('Muslims hate gays and want them dead. Islam is the biggest threat to the LGBT folks on this planet. This is probably only the beginning of this sort of thing.', 158, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16], [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]], ['Muslims hate gays', 'them dead. Islam is t'], 1.0),\n",
       "       ('And yet he won several elections including the toughest one in the land.  Perhaps he knows more than you lefties give him credit for as he makes the left look more foolish daily.', 178, '[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]', [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175]], ['And yet he won several elections including the toughest one in the land.  Perhaps he knows more than you lefties give him credit for as he makes the left look more foolish dail'], 1.0)],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "new_train[new_train['words_cut']>0].apply(lambda x: (x['text'],len(x['text']),x['spans'],x['contiguous_spans'],print_contiguous_spans(x['text'],x['contiguous_spans']),x['words_cut']),axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if any spans end or start with space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def check_if_start_or_end_with_whitespace(text,contiguous_spans):\n",
    "    start_or_end_with_space = []\n",
    "    for i in contiguous_spans:\n",
    "        s_e = 0\n",
    "        if text[i[0]] in string.whitespace:\n",
    "            s_e+=1\n",
    "        if text[i[-1]] in string.whitespace:\n",
    "            s_e+=1\n",
    "        start_or_end_with_space.append(s_e)\n",
    "    return start_or_end_with_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_end_with_space(df):\n",
    "    df['start_or_end_with_space'] = df.apply(lambda x: np.sum(check_if_start_or_end_with_space(x['text'],x['contiguous_spans'])),axis=1)\n",
    "    return df['start_or_end_with_space'].sum(),df['start_or_end_with_space'].mean(),df['start_or_end_with_space'].std()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['20.00', '0.00', '0.05']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in start_end_with_space(new_train)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['1.00', '0.00', '0.04']\n"
     ]
    }
   ],
   "source": [
    "print(['%.2f'% i for i in start_end_with_space(trial)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([('I am watching Goodale on TV giving statements about this. He is such an ass. What a slime bucket.  i hope he knows the depth of disgust he is creating for himself and his most beloved Justin trudeau. Will the media  hold Trudeau to task as Prime Minister and ask  questions him real questions when he gets back from his Pride Parade across Europe?  Or will they  ask him low ball questions about the weather to save him embarrassment of looking like an idiot.', 459, 1.0, ['He is such an ass', ' i hope he knows the depth of disgust he is creating for himself and his most beloved Justin trudea', 'Or will they  ask him low ball questions about the weather to save him embarrassment of looking like an idiot']),\n",
       "       ('Most of trump supporters in red states rely on the government in on way or another for support and there is no way they voted for trump to cut those programs.  They want more government support, not less.  \\ntrump promises the moon and only stupid people believe him.', 266, 1.0, ['Most of trump supporters in red states rely on the government in on way or another for support and there is no way they voted for trump to cut those programs.  They want more government support, not less.  \\ntrump promises the moon and only stupid people believe ']),\n",
       "       ('Trump is a danger to America.  He should not be allowed to putt he world at danger by being the sole authority to drop nukes on Korea and end the world as we know it.  This jerk is a fool.  Shame on Republicans and their disgraceful base for putting AMERICA IN SUCH DANGER.', 273, 1.0, [' This jerk is a fool']),\n",
       "       (\"T:  How very civil of you.  Disgusting?  No, disgusting is condoning violence because it suits your political racist bigotry, that's disgusting.\", 144, 1.0, [\" How very civil of you.  Disgusting?  No, disgusting is condoning violence because it suits your political racist bigotry, that's disgusting\"]),\n",
       "       (\"Indeed...every time I see some maudlin fool do this, it's hard not to flashback to the last time I saw a cat or dog licking its own a$$, or--in the case of dogs--eating its own feces.  Cats eat parasite-infected mice instead.\\n\\nNatural selection is always on the lookout for the weak and stupid.  It cures all ills.\", 314, 1.0, ['maudlin fool', 'a$$', '-eating its own feces', ' Cats eat parasite', 'infected', 'stupid']),\n",
       "       ('Sex is a product of lust, not love.  It is my understanding that for many homosexuals, lust is equated with love, and that they rationalize that penetrating a same-sex partner is an expression of love.  The 2am crowd at the local gay bar is filled with guys who are quickly falling in love.', 290, 1.0, ['Sex is a product of lust, not love.  It is my understanding that for many homosexuals, lust is equated with love, and that they rationalize that penetrating ']),\n",
       "       (\"I would expect nothing less from a lil' tRump bunny.  $3.5 billion.  Maybe.  He claims a worth of $10 billion.  Makes 3.5 pretty puny.  And not much of a fortune compared to what his daddy gave him.  A 'smart' business man could have invested in the stock market and done considerably better.  tRump:  just a stupid huckster.  And i do mean stupid.\", 348, 1.0, [' just a stupid huckster.  And i do mean stupid']),\n",
       "       ('Once again...a person who advocates for dehumanization and spews a nonstop stream of hatred - who then preaches about respecting other humans comes off as hypocritical and ignorant.  (Oops, there I go again with my \"deranged\" \"evil\" \"harassment\")  By the way, what is with your affinity for the term \"pond scum\"?', 312, 1.0, ['person who advocates', 'hypocritical and ignorant', ' By the way, what is with your affinity for the term \"pond scu']),\n",
       "       ('Ridiculous comment.  Hundreds of Syrian refugees who have come to Canada have Jan. 1st as their birth date. When they arrive from Syria at the Turkish border, they have no passport, birth certificate, drivers licence or any sort of identification.  This kind of \"extreme vetting\" is dangerously unacceptable for refugees coming from terrorist hot spots like Syria.', 364, 1.0, ['Ridiculous comment', ' This kind of \"extreme vetting\" is dangerously unacceptable for refugees coming from terrorist hot spots like Syri']),\n",
       "       ('Newsflash:  they aren\\'t the brightest bulbs in the chandelier.  The first clue is how much the left wants the here.  The left likes losers.  That\\'s their power base and it\\'s all about power.  Know a few schoolteachers and privately they tell me how difficult it is to teach \"Latinos\".  That\\'s because they are stupid.', 317, 1.0, ['h:  they ', 'stupid']),\n",
       "       ('Settle down.   You’re out of control.  trump can say it & you’re perfectly fine hypocrite.', 90, 1.0, [' trump can say it & you’re perfectly fine hypocrite']),\n",
       "       ('As Bill Maher put it: \"is this guy just another stupid white man or what?\"', 74, 1.0, ['t: \"is ', 'stupid']),\n",
       "       ('I love throwing CONservatives a bone every now and than.  That way the rest of us can click on the React smily face and flush out the wrong-winger naysayers.  It works every damn time.  Yuk, yuk, yuk.  Now get outta here.', 221, 1.0, [' It works every damn time']),\n",
       "       (\"Let's see.  We have a Beltline Freeway called the Randy Pape after someone most people have never heard of, yet the city council debates the pros and cons of Kesey Square?  Stupid is as stupid does.  It's the perfect name. Just move on and accomplish something meaningful like solving the homeless crisis or better yet ... resign and let others do something. What an utter waste of time and effort.\", 398, 1.0, ['Freeway', ' Stupi', 'stupid']),\n",
       "       (\"You're lying of course, as you always do.  I don't put everybody down, and never have.\\n\\nI'm bigoted only against stupid and ignorant people who know nothing about the subjects they comment on.\", 192, 1.0, [\"You're lying of course, as you always do.  I don't put everybody down, and never have.\\n\\nI'm bigoted only against stupid and ignorant people who know nothing about the subjects they comment \"]),\n",
       "       (\"Roof is not really an ignorant redneck or KKK white trash--his family seemed quite well-off when he was a child and according to reports he was bright in school.   He's clearly not normal--his OCD is likely from Asperger's or autism.  He got into drugs and someone like him, very obviously, should not have been permitted to carry a gun.\", 337, 1.0, ['ignorant redneck', \"  He's clearly not normal--his OCD is likely from Asperger's or auti\"]),\n",
       "       ('The :Trump Chumps\" voted for a commie backed regime.  Fools.', 60, 1.0, ['Chumps', ' Fools']),\n",
       "       (\"It was pathetic when Harper attacked anyone who criticized him with the CRA.  I bet you can't wait to see him behind bars.\", 122, 1.0, ['It was pathetic when Harper attacked anyone who criticized him with the CRA', \" I bet you can't wait to see him behind bar\"]),\n",
       "       ('burned out for 6 yrs? too bad.  jerk cop should have quit 5 yrs ago....', 71, 1.0, [' jer']),\n",
       "       (\"These aren't womens' marches.  They are puppets' marches.  Mindless puppets of the Washington Post, New York Times and the rest of the world's liberati media.  Got to feel sorry for these women.\", 194, 1.0, [' Got to feel sorry for these wome'])],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "new_train[new_train['start_or_end_with_space']>0].apply(lambda x: (x['text'],len(x['text']),x['start_or_end_with_space'],print_contiguous_spans(x['text'],x['contiguous_spans'])),axis=1).values"
   ]
  },
  {
   "source": [
    "Clean out spans which are half in, remove trailing and beginning spaces"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word_by_character_index(text, idx):\n",
    "    if(not text[idx].isalnum()):\n",
    "        backward = idx\n",
    "        forward = idx\n",
    "        while(backward>-1 and not text[backward].isalnum()):\n",
    "            backward-=1\n",
    "        while(forward<len(text) and text[forward].isalnum()):\n",
    "            forward+=1\n",
    "\n",
    "        return text[backward+1:forward], backward+1,forward-1\n",
    "    else:\n",
    "        return text[idx], idx, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'[0, 1, 2, 3, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71]'"
      ]
     },
     "metadata": {},
     "execution_count": 201
    }
   ],
   "source": [
    "new_train.loc[20,'spans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Kill some more kids and then complain about guns, LOL the left is a joke'"
      ]
     },
     "metadata": {},
     "execution_count": 202
    }
   ],
   "source": [
    "new_train.loc[20,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('kids', 15, 18)"
      ]
     },
     "metadata": {},
     "execution_count": 203
    }
   ],
   "source": [
    "find_word_by_character_index(new_train.loc[20,'text'],15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text,contiguous_spans):\n",
    "    new_contiguous_spans = []\n",
    "\n",
    "    for i in contiguous_spans:\n",
    "        start = i[0] \n",
    "        end = i[-1]\n",
    "\n",
    "        if start==0 and end==len(text)-1:\n",
    "            new_contiguous_spans.append([start,end])\n",
    "\n",
    "        elif start==0:\n",
    "            if text[end].isalnum() and text[end+1].isalnum():\n",
    "\n",
    "                full_word,full_start,full_end = find_word_by_character_index(text,end)\n",
    "                cut_word_len = end-full_start+1\n",
    "                if(cut_word_len*2>=len(full_word)):\n",
    "                    new_contiguous_spans.append([start,full_end])\n",
    "                else:\n",
    "                    new_contiguous_spans.append([start,full_start-1])\n",
    "\n",
    "\n",
    "        elif i[-1]==len(text)-1:\n",
    "            if text[start].isalnum() and text[start-1].isalnum():\n",
    "                full_word, full_start,full_end = find_word_by_character_index(text,start)\n",
    "                cut_word_len = full_end-start+1\n",
    "                if(cut_word_len*2>=len(full_word)):\n",
    "                    new_contiguous_spans.append([full_start,end])\n",
    "                else:\n",
    "                    new_contiguous_spans.append([full_end+1,end])\n",
    "                \n",
    "                \n",
    "        else:\n",
    "            new_start = start\n",
    "            new_end = end\n",
    "           \n",
    "            if text[start].isalnum() and text[start-1].isalnum():\n",
    "                full_word, full_start,full_end = find_word_by_character_index(text,start)\n",
    "                cut_word_len = full_end-start+1\n",
    "                if(cut_word_len*2>=len(full_word)):\n",
    "                    new_start = full_start\n",
    "                else:\n",
    "                    new_start = full_end+1\n",
    "\n",
    "            if text[end].isalnum() and text[end+1].isalnum():\n",
    "                full_word, full_start,full_end = find_word_by_character_index(text, end)\n",
    "                cut_word_len = end-full_start+1\n",
    "                if(cut_word_len*2>=len(full_word)):\n",
    "                    new_end = full_end\n",
    "                else:\n",
    "                    new_end = full_start-1\n",
    "            new_contiguous_spans.append([new_start,new_end])\n",
    "    ## Remove Spaces from span beginning and end\n",
    "\n",
    "    newest_contiguous_spans = []\n",
    "    for i in new_contiguous_spans:\n",
    "        start = i[0]\n",
    "        end = i[-1]\n",
    "        while start<=end:\n",
    "            if(not (text[start].isalnum()) or not (text[end].isalnum())):\n",
    "                if not (text[start].isalnum()):\n",
    "                    start+=1\n",
    "                if not (text[end].isalnum()):\n",
    "                    end-=1\n",
    "            else:\n",
    "                break\n",
    "        if(start<=end):\n",
    "            newest_contiguous_spans.append([start,end])\n",
    "    return newest_contiguous_spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Hello How are you sir, My name is Gunjan Chhablani?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "contiguous_spans = get_continuous_spans([1,2,3,4,6,7,11,12,13,14,15,16,17, 18, 19, 22,23,24,25,30,31,32,33,34,35,36, 41,42,43,44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['ello', 'Ho', 're you si', ' My ', ' is Gun', 'Chha']"
      ]
     },
     "metadata": {},
     "execution_count": 286
    }
   ],
   "source": [
    "print_contiguous_spans(text,contiguous_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_contiguous_spans = clean_text(text,contiguous_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello', 'How', 'are you sir', 'My', 'is Gunjan']"
      ]
     },
     "metadata": {},
     "execution_count": 288
    }
   ],
   "source": [
    "print_contiguous_spans(text,new_contiguous_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = new_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train['contiguous_spans'] = clean_train.apply(lambda x: clean_text(x['text'],x['contiguous_spans']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trial = trial.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trial['contiguous_spans'] = clean_trial.apply(lambda x:clean_text(x['text'],x['contiguous_spans']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 303
    }
   ],
   "source": [
    "start_end_with_space(clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 304
    }
   ],
   "source": [
    "start_end_with_space(clean_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_cut_count_clean(df):\n",
    "    df['words_cut'] = df.apply(lambda x: np.sum(check_if_word_cut(x['text'],x['contiguous_spans'])),axis=1)\n",
    "    return df['words_cut'].sum(),df['words_cut'].mean(),df['words_cut'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 308
    }
   ],
   "source": [
    "words_cut_count_clean(clean_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.0, 0.0, 0.0)"
      ]
     },
     "metadata": {},
     "execution_count": 309
    }
   ],
   "source": [
    "words_cut_count_clean(clean_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train.to_csv('../data/clean_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trial.to_csv('../data/clean_trial.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train = pd.read_csv('../data/clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trial = pd.read_csv('../data/clean_trial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spans_from_contiguous(contiguous_spans):\n",
    "    spans = []\n",
    "    for i in eval(contiguous_spans):\n",
    "        spans+=list(range(i[0],i[-1]+1))\n",
    "    return spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train['spans'] = clean_train['contiguous_spans'].apply(get_spans_from_contiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trial['spans'] = clean_trial['contiguous_spans'].apply(get_spans_from_contiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train[['spans','text']].to_csv('../data/clean_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_trial[['spans','text']].to_csv('../data/clean_trial.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train.to_csv('../data/modified_train.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_text(df):\n",
    "    df['#tokens'] = df.apply(lambda x: len(tokenizer.tokenize(x['text'])),axis=1)\n",
    "    df['#words'] = df.apply(lambda x: len(x['text'].split()),axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = []\n",
    "for df in [clean_train,clean_trial,new_train,trial]:\n",
    "    tokenize_text(df)\n",
    "    lists.append(['%.2f' % i for i in (df['#tokens'].mean(),df['#tokens'].std(),df['#tokens'].max(),df['#tokens'].min())]+['%.2f' % i for i in (df['#words'].mean(),df['#words'].std(),df['#words'].max(),df['#words'].min())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "|               |      0 |      1 |      2 |      3 |\n|:--------------|-------:|-------:|-------:|-------:|\n| #Tokens(mean) |  47.53 |  46.1  |  47.53 |  46.1  |\n| #Tokens(std)  |  45.46 |  43.82 |  45.46 |  43.82 |\n| #Tokens(max)  | 335    | 234    | 335    | 234    |\n| #Tokens(min)  |   1    |   1    |   1    |   1    |\n| #Words(mean)  |  35.97 |  35.01 |  35.97 |  35.01 |\n| #Words(std)   |  34.97 |  34.42 |  34.97 |  34.42 |\n| #Words(max)   | 192    | 182    | 192    | 182    |\n| #Words(min)   |   1    |   1    |   1    |   1    |\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(lists, columns=[\"#Tokens(mean)\",\"#Tokens(std)\",\"#Tokens(max)\",\"#Tokens(min)\",\"#Words(mean)\",\"#Words(std)\",\"#Words(max)\",\"#Words(min)\"]).T.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}